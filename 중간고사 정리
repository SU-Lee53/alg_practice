- 알고리즘:
    문제를 해결하기 위한 단계적인 절차를 의미
- 알고리즘은 요리법과 유사:
    단계적인 절차를 따라 하면 주어진 문제의 해를 찾는다
- 효율적인 알고리즘 고안이 중요:
    주어진 문제에 대해 여러 종류의 알고리즘이 있을 수 있으나, 항상 보다 효율적인 알고리즘을 고안하는 것이 중요
    => 결과가 동일하지만 더 빨리 수행될 경우 선택하지 않을 이유가 없음
    => 정확한 답을 구하는것이 너무 오래걸리거나 불가능한 경우도 근사값을 빠르게 구할 수 있다면 사용해야함

- 효율적인 알고리즘:
    - 순차탐색 vs 이진탐색 vs 해시테이블:
        O(n) vs O(log n) vs 상수시간
    - 거스름돈: 그리디 알고리즘 vs 동적 계획법(Dynamic Programming):
        : 동전이 정수배로 늘어나기 때문에 그리디 알고리즘 사용가능
        : 아니면 동적 계획법
    - 한붓그리기 == Euler Circuit -> DFS vs 다른방법:
        : DFS: 순차탐색과 유사, 갈때까지 가보고 안되면 Back Tracking
        : Cycle Check: 외길이면 가고 아니면 사이클이 있는 경로로 진행(다른 길은 사이클을 돌고와서 갈수 있으니까)
            : Cycle Check: 그 간선을 지우고 다른 길로 지운 간선의 끝에있는 노드에 갈수 있다면 Cycle
    - 미로찾기 -> 더 쉬운 문제로 변형, 문제의 법칙을 해쳐선 안됨
        : 오른손 법칙으로 미로를 펼치면 더 쉬운 방법으로 미로찾기 가능(모든 벽이 연결되어 있어야함)
    - 가짜 동전 찾기 -> 후보군을 더 많이 줄이는 방법 -> 시간복잡도에서 차수가 달라짐(비교불가능한 차이), 차수가 같을때 계수를 줄이려는 노력도 필요
        : 시간복잡도: 평균 vs 최악
            : 상황에 따라 다르다
    - 독이 든 술단지: n개의 술단지 중 독이 든 술단지를 찾는법
        : 2진수 형태로 변환해서 log n명의 신하로 찾을 수 있음


- 알고리즘의 일반적 특성
    - 정확성 : 주어진 입력에 대해 정확한 해를 구할수 있어야함
    - 수행성
    - 유한성 : 유한시간안에 끝나야함
    - 효율성 : 효율적일수록 알고리즘의 가치가 높아진
- 유클리드의 최대공약수 알고리즘 : 큰수에서 작은수를 뺀 수와 작은수와의 최대공약수와 같다
    - 뺄셈과 루프만 있다면 누구나 구할수 있다
- * 알고리즘의 표현방법 : 알고리즘의 각 단계는 보통 말로 서술할 수 있으며 프로그래밍 언어로만 사용할 필요는 없음
    - 자연어
    - 의사코드(pseudo code): 프로그래머라면 누구나 알아볼수 있게, 빠르게 표현 가능
    - 플로우 차트(flow chart): 프로그래머가 아닌 사람도 이해가능
    - 특정 언어 사용
- * 알고리즘의 효율성 표현: 수행시간, 사용되는 메모리 크기(+ 개발복잡도)
    - 시간복잡도, 공간복잡도: 주로 시간복잡도를 사용
    - 시간복잡도: 알고리즘이 수행하는 기본적인 연산의 횟수
- * 알고리즘의 복잡도 표현방법: 최악, 평균, 최선
    - 최악: 상한의 의미 -> 보통은 최악의 경우를 사용
    - 평균: 일반적으로 균등한 분포를 가정 -> 평균을 사용할 때도 있음(퀵소트의 경우)
    - 최선: 하한
- * 복잡도의 점근적 표기: n이 무한대로 커질때 표현하기 위함
    - 빅오 : 상한
    - 빅 오메가 : 하한
    - 빅 세타 : 둘다 만족 -> 다항식에서 최고 차수 할만을 취한 뒤, 그 항의 계수를 제거하여 구한다
        - 실제로는 빅세타를 가지고 빅오로 표기함(사전적인 의미와 실전에서 의미가 다름)
    - 포함관계
    - O(1), O(logn), O(n), O(nlogn), O(n^2), O(2^n), O(n!), .....
- 효율적인 알고리즘의 필요성: 효율적인 하드웨어의 개발보다 중요


- 정렬 알고리즘
    - 내부정렬 vs 외부정렬: 메인 메모리에 다 올릴수 있는가의 여부
    - 최근 많이 사용하는 정렬: Tim Sort -> Merge Sort 를 수행하다가 Insertion Sort로 전환 -> Stable하고 Quick Sort보다 빠름

    - 버블정렬
        - 장점: 구현하기 쉬움
        - 단점: 매우느림 -> 최적화 가능(마지막에 교환이 일어난 곳의 직전까지만 수행)
        - 시간복잡도
            - 최선: O(n) -> 이미 정렬되어 있는 경우
            - 최악: O(n^2)
    - 선택정렬
        - 장점: n^2중에선 빠름(원소간의 자리바꿈 횟수가 최소이기 때문), 입력에 민감하지 않음(단점일수도 있음)
        - 단점: 느림, 어떠한 경우에도 O(n^2)의 시간이 걸림
        - 시간복잡도: 항상 O(n^2)
    - 삽입정렬: 2번째 원소부터 적절하게 왼쪽으로 옮김, 스왑하면서 옮기지 않고 따로 빼놓고 적절한 위치의 오른쪽 원소들을 민다음 넣음
        - 장점: 어느정도 정렬되어 있다면 매우빠름
        - 단점: 아니면 느림
        - 시간복잡도:
            - 최선: O(n)
            - 최악: O(n^2)
    - 선택정렬 vs 삽입정렬: 사용 조건에 따라 다름
        - 삽입정렬은 거의 정렬된 경우 O(n)에 가까운 시간이 걸림

    - 쉘 정렬: 간격(gap)을 이용한 삽입정렬
        - gap을 이용하여 여러개의 sub-array로 나누어 삽입정렬
        - 주인공의 선택 방법에 따라 4중루프에서 3중루프로 줄일 수 있다
        - 장점:  - 간격에 따른 그룹별 정렬 방식이 하드웨어로 정렬 알고리즘을 구현하는데 매우 적합하므로 임베디드 시스템에서 주로 사용
                - 크기가 매우 크지 않은경우 매우 좋음(크기가 작을때 힙보다 빠르기도 함, 그러나 역전되고 나면 비교불가능한 차이로 벌어짐)
        - 시간복잡도 : 정확히 알려진 바가 없음, 일반적으로 O(n^2/3)으로 알려짐

    - 힙 정렬: Heap이라는 이진트리 형태를 이용하여 정렬
        - 최대 Heap 트리를 배열로 만들수 있음
        - 계속 DownHeap과정을 거치며 루트 노드를 맨끝으로 뺌(사이즈도 하나씩 줄임)
        - DownHeap은 양쪽 트리가 모두 힙상태이어야 하므로 맨끝부터 수행해야함
        - n개의 노드가 있을때 n/2(0부터 시작할 경우 (n/2)-1) 만큼의 노드만 자식이 있으므로 여기서부터 DownHeap을 수행하면 됨
        - 1부터 시작하면 수식이 쉬워지는 대신 1칸이 낭비됨, 수식은 별도로 정리해놓았음(아래참고, 100프로 시험)
        - 최초 최대힙 알고리즘(DownHeap())은 O(n)의 시간이 걸림
        - DownHeap():
            - 자식들 중 더 큰값을 가진 자식과 부모를 비교하여 자식이 더 클경우 스왑
            - 스왑됬다면 자식트리의 부모가 변경되었으므로 그 아래도 재귀적으로 DownHeap() 호출
        - 장점: 이론적으로 완벽함(추가메모리 필요X, 어떤 상황에서도 O(nlogn)
        - 단점: 캐시 미스가 많이 일어날수밖에 없어 다른 O(nlogn)정렬보다 느림
        - 시간복잡도:
            O(nlogn): 힙 만드는데 O(n), n-1번 반복, DownHeap()에 nlogn, 전부 곱하고 계수 떼면 nlogn

                                 0
                        1		         2
                     3     4          5     6
                   7   8 9   10     11 12 13 14

                -> tree size = 15
                -> n's parent = (n-1) // 2
                -> n's left child = 2n+1
                -> n's right child = 2n+2
                -> n is root = n == 0
                -> n has left child = 2n+1 < treesize
                -> 시험문제


                                  1
                        2		          3
                     4      5          6     7
                   8   9 10   11     12 13 14 15

                -> tree size = 15
                -> n's parent = n // 2
                -> n's left child = 2n
                -> n's right child = 2n+1
                -> n is root = n == 1
                -> n has left child = 2n <= treesize

    - 정렬 문제의 하한: 비교 정렬에 한해서 Ω(nlogn), Counting 정렬이나 기수정렬같은 경우 nlogn보다 빠름
        : Counting Sort -> O(n+r), Radix Sort -> O(k(n+r)) (n: 자료의 갯수, r: 자료의 종류, k: 반복횟수)





